{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from fair_research_login import NativeClient\n",
    "\n",
    "client = NativeClient(client_id='7414f0b4-7d05-4bb6-bb00-076fa3f17cf5')\n",
    "tokens = client.login(\n",
    "    requested_scopes=['urn:globus:auth:scope:transfer.api.globus.org:all',\n",
    "                      \"https://auth.globus.org/scopes/facd7ccc-c5f4-42aa-916b-a0e270e2c2a9/all\", \n",
    "                      'email', 'openid'],\n",
    "    no_local_server=True,\n",
    "    no_browser=True)\n",
    "\n",
    "transfer_token = tokens['transfer.api.globus.org']['access_token']\n",
    "funcx_token = tokens['funcx_service']['access_token']\n",
    "headers = {'Authorization': f\"Bearer {funcx_token}\",'Transfer': transfer_token, 'FuncX': f\"{funcx_token}\"}\n",
    "print(f\"Headers: {headers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://127.0.0.1:5000/upload_def_file\"\n",
    "definition_ids = []\n",
    "\n",
    "for i in range(3):\n",
    "    file_name = \"Dockerfile\"\n",
    "    file_path = \"Dockerfile\"\n",
    "    my_files = {\"file\": (file_name, open(file_path,\"rb\"))}\n",
    "    response = requests.post(url, files=my_files, headers=headers)\n",
    "    definition_id = response.text\n",
    "    definition_ids.append(definition_id)\n",
    "    print(definition_id)\n",
    "\n",
    "print(definition_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://127.0.0.1:5000/build\"\n",
    "build_ids = []\n",
    "\n",
    "for idx, definition_id in enumerate(definition_ids):\n",
    "    my_data = {\"definition_id\": definition_id, \"to_format\": \"docker\", \n",
    "               \"container_name\": \"my_container_{}\".format(idx)}\n",
    "    response = requests.post(url, json=my_data, headers=headers)\n",
    "    build_id = response.text\n",
    "    build_ids.append(build_id)\n",
    "    print(build_id)\n",
    "\n",
    "\n",
    "print(build_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "url = \"http://127.0.0.1:5000/build\"\n",
    "keep_printing = True\n",
    "import time\n",
    "import json\n",
    "from IPython.display import clear_output\n",
    "while keep_printing:\n",
    "    clear_output(True)\n",
    "    is_done = []\n",
    "    for idx, build_id in enumerate(build_ids):\n",
    "        response = requests.get(url, json={\"build_id\": build_id} , headers=headers)\n",
    "        if json.loads(response.text)[\"build_status\"] == \"success\":\n",
    "            is_done.append(True)\n",
    "        else:\n",
    "            is_done.append(False)\n",
    "        print(time.time())\n",
    "        print(response.text)\n",
    "    if all(is_done):\n",
    "        keep_printing = False\n",
    "    time.sleep(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stuff to work on for next time:\n",
    " - Try to see if restarting docker fixes the 500 Server Error: Internal Server Error (\"a disk usage operation is already running\") error\n",
    " - Add some sort of cleanup for when the build fails\n",
    " - Add retrying stuff\n",
    " - Scale big time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
